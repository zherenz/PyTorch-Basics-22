{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPBRREdYUO5GOhYeND/Zz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zherenz/PyTorch-Basics-22/blob/main/torch_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader<br>\n",
        "torch.utils.data.DataLoader<br>\n",
        "torchvision.datasets<br>\n",
        "torchvision.datasets.ImageFolder<br>"
      ],
      "metadata": {
        "id": "x76JKTCA1bMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torchvision.datasets"
      ],
      "metadata": {
        "id": "D1s15GIygym_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xi9rrnF1Sz2"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "# torchvision.datasets.FashionMNIST\n",
        "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=False, transform=ttf.ToTensor())\n",
        "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=False, transform=ttf.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# torchvision.datasets.CIFAR10\n",
        "train_set = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/deep_learning/data', train=True, download=False, transform=ttf.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "# torchvision.datasets.ImageNet(root: str, split: str = 'train', **kwargs: Any)\n",
        "imagenet_data = torchvision.datasets.ImageNet('path/to/imagenet_root/')\n",
        "data_loader = torch.utils.data.DataLoader(imagenet_data,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=args.nThreads)\n",
        "\n",
        "# We have loaded that dataset into the DataLoader and can iterate through the dataset as needed. \n",
        "# Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torchvision.datasets.ImageFolder"
      ],
      "metadata": {
        "id": "_Mj1K9VJ-LP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as ttf\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(train_path, transform=ttf.ToTensor())\n",
        "val_data = torchvision.datasets.ImageFolder(val_path, transform=ttf.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_worker=4, shuffle=False)"
      ],
      "metadata": {
        "id": "bTfqD5f6asTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = [ttf.ToTensor(), ttf.RandomHorizontalFlip(), ttf.RandomAffine(degrees=(-15, 15), scale=(0.98, 1.03)), ttf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
        "val_transforms = [ttf.ToTensor(), ttf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
        "\n",
        "# root/dog/xxx.png\n",
        "# root/dog/xxy.png\n",
        "# root/dog/[...]/xxz.png\n",
        "\n",
        "# root/cat/123.png\n",
        "# root/cat/nsdf3.png\n",
        "# root/cat/[...]/asd932_.png"
      ],
      "metadata": {
        "id": "6Hm8tnYy3e9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model<br>\n",
        "torch.nn.Module<br>\n",
        "torch.nn.Sequential<br>"
      ],
      "metadata": {
        "id": "T2INiQVNhnaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Module (LeNet) <br>"
      ],
      "metadata": {
        "id": "_z00VQ5mkxiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = torch.flatten(self.num_flat_features(x), start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "model = Model()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "U4TPpn2Gh1fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Sequential"
      ],
      "metadata": {
        "id": "JERW7tfrlpLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, 3),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2,2),\n",
        "    \n",
        "    nn.Conv2d(32, 64, 3),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2,2),\n",
        "    # print the size of the output --> output.size() \n",
        "    # to find out the input size of fc \n",
        "    \n",
        "    # flatten from 2nd dimesion (batch)\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 6 * 6, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(4096, 10)\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bcS4slZ-lvWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "iGSZcFQWmo2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "criterion = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
        "criterion = torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
        "criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "criterion = torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean', beta=1.0)"
      ],
      "metadata": {
        "id": "IEs8Aul6nQ3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BCE-Dice Loss"
      ],
      "metadata": {
        "id": "gMpS7RoQaKD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        inputs = F.sigmoid(inputs)       \n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()                     \n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "        \n",
        "        return Dice_BCE"
      ],
      "metadata": {
        "id": "fkwX8HdbaHXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Eval"
      ],
      "metadata": {
        "id": "tbnUK7lroB1M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hllh2Q8WoGVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}